# -*- coding: utf-8 -*-
"""Amazon_review.ipynb
Automatically generated by Colaboratory.
Original file is located at
    https://colab.research.google.com/drive/1aKD2rMvAa4B7KesyMi6Oxwla4Es23cte
# **Amazon product Review Analysis**
### 1 Web scraping product review
"""

#resources https://github.com/MarcSkovMadsen/awesome-streamlit#awesome-resources
#https://github.com/Jcharis/Streamlit_DataScience_Apps

from bs4 import BeautifulSoup
import requests
import emoji
import nltk
import enchant
import pandas as pd
from dateutil.parser import parse
import numpy as np
#from flask import Flask, render_template, url_for, request
from nltk.corpus import stopwords
import streamlit as st
nltk.download('stopwords')

from nltk.stem import SnowballStemmer
import pickle
from sklearn.cluster import KMeans
from sklearn.feature_extraction.text import TfidfTransformer
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.naive_bayes import MultinomialNB
#from sklearn.externals import joblib
import string
import time


def getReview_link(s, u):
    if s != "stop":
        cookie = {}
        header = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/77.0.3865.90 Safari/537.36'}
        uu = requests.get(u, cookies=cookie, headers=header)
        soup = BeautifulSoup(uu.content, 'html.parser')
        rev = soup.find('div', id="reviews-medley-footer")
        t = rev.find('a').get('href')
        r_u = "https://www.amazon.in" + t + "&sortBy=recent"
        return r_u


def getReviews(url, pg):
    cookie = {}
    header = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/77.0.3865.90 Safari/537.36'}

    ur = url + "&pageNumber=" + str(pg) + "&sortBy=recent"
    page = requests.get(ur, cookies=cookie, headers=header)
    r_h = []
    r_b = []
    r_t = []

    if page.status_code == 200:
        soup = BeautifulSoup(page.content, 'html.parser')
        r = soup.find('div', id="cm_cr-review_list")

        if r == "f":
            return r_h, r_b, r_t, pg
        else:

            ty = soup.find('div', class_="a-section a-spacing-none review-views celwidget")

            rt = ty.find_all("a", {'data-hook': "review-title"})

            for i in rt:
                if i is None:
                    r_h.append(None)
                else:
                    v = i.get_text()
                    v = v.strip("\n")

                    r_h.append(v)
            rb = soup.find_all("span", {'data-hook': "review-body"})
            for i in rb:
                if i is None:
                    r_b.append(None)
                else:
                    v = i.get_text()
                    v = v.strip("\n")
                    r_b.append(v)
            rti = soup.find_all("span", {'data-hook': "review-date"})
            for i in rti:
                if i is None:
                    r_t.append(None)
                else:

                    t = i.get_text()
                    date = parse(t, fuzzy=True, dayfirst=True)
                    r_t.append(date)

            nextp = soup.find("ul", class_="a-pagination")
            npg = 0
            if (nextp.find("li", class_="a-disabled a-last")) is not None:
                return r_h, r_b, r_t, npg
            elif (nextp.find("li", class_="a-last")) is not None:

                npg = pg + 1
                return r_h, r_b, r_t, npg


#app = Flask(__name__)


#@app.route('/')
#def home():
    #return render_template('index.html')


#@app.route('/Review_extract', methods=['POST'])
def Review_extract(purl):
    p=purl
    #if request.method == 'POST':
        #product_u= request.form.get('comment')
        #print(product_u)
        #message = request.form.get('message')
        #p = str(product_u)

    cookie = {}
    header = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/77.0.3865.90 Safari/537.36'}

    Reviews = pd.DataFrame()
    page = requests.get(p, cookies=cookie, headers=header)
    if page.status_code == 200:
        st = page
    else:
        st = "stop"
    H = []
    B = []
    D = []
    rev_link = getReview_link(st, p)

    pg = 1
    ntpg = 1
    while (pg >= ntpg):

        #my_bar = st.progress(0)
        #for percent_complete in range(pg):
            #time.sleep(0.1)
            #my_bar.progress(percent_complete + 1)
        print(pg)
        r_t = []
        r_h = []
        r_b = []
        r_h, r_b, r_t, ntpg = getReviews(rev_link, pg)

        H.extend(r_h)
        B.extend(r_b)
        D.extend(r_t)
        if ntpg > pg:
            pg = ntpg
            continue
        else:
            break
    Reviews = pd.DataFrame(({"Review_title": H,
                             "Review_body": B,
                             "Review_date": D}))
    return Reviews

def main():
    st.title("Review Miner  ")
    st.text("By Santosh A Patil")
    marketplace = ["amazon.in","flipkart.in"]
    choice = st.sidebar.selectbox("Select Marketplace",marketplace)
    if choice == "amazon.in":
        st.subheader("Amazon.in")

        product_url = st.text_input("Enter The Product url [Eg: ","paste or type URL here")
        if st.button('Analyze Reviews'):
            if "amazon.in" in product_url:
                data=Review_extract(product_url)
                D=data.head()
                st.dataframe(D)
            else:
                st.text("Enter a amazon.in starting product URL")
        else:
            st.write("Press the above button..")

main()




    #return render_template('index.html', prediction_text='Total Reviews Extracted : {}'.format(no_reviews))


#if __name__ == '__main__':
    #app.run(debug=True)
